{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPX2fQ7IQnvta5RTH7JTxlF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kessingtonosazee/GCP_Project_1/blob/master/Linear_Regression2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1PPixxhA6RyV"
      },
      "outputs": [],
      "source": [
        "# Predicting Price with Size, Location, and Neighborhood\n",
        "\n",
        "# Libraries\n",
        "import warnings\n",
        "from glob import glob\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import wqet_grader\n",
        "from category_encoders import OneHotEncoder\n",
        "from IPython.display import VimeoVideo\n",
        "from ipywidgets import Dropdown, FloatSlider, IntSlider, interact\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LinearRegression, Ridge  # noqa F401\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.utils.validation import check_is_fitted\n",
        "\n",
        "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
        "wqet_grader.init(\"Project 2 Assessment\")\n",
        "\n",
        "# Prepare Data\n",
        "# create a wrangle function to prepare data\n",
        "def wrangle(filepath):\n",
        "    # Read CSV file\n",
        "    df = pd.read_csv(filepath)\n",
        "\n",
        "    # Subset data: Apartments in \"Capital Federal\", less than 400,000\n",
        "    mask_ba = df[\"place_with_parent_names\"].str.contains(\"Capital Federal\")\n",
        "    mask_apt = df[\"property_type\"] == \"apartment\"\n",
        "    mask_price = df[\"price_aprox_usd\"] < 400_000\n",
        "    df = df[mask_ba & mask_apt & mask_price]\n",
        "\n",
        "    # Subset data: Remove outliers for \"surface_covered_in_m2\"\n",
        "    low, high = df[\"surface_covered_in_m2\"].quantile([0.1, 0.9])\n",
        "    mask_area = df[\"surface_covered_in_m2\"].between(low, high)\n",
        "    df = df[mask_area]\n",
        "\n",
        "    # Split \"lat-lon\" column\n",
        "    df[[\"lat\", \"lon\"]] = df[\"lat-lon\"].str.split(\",\", expand=True).astype(float)\n",
        "    df.drop(columns=\"lat-lon\", inplace=True)\n",
        "\n",
        "    # Get place name\n",
        "    df[\"neighborhood\"] = df[\"place_with_parent_names\"].str.split(\"|\", expand=True)[3]\n",
        "    df.drop(columns=\"place_with_parent_names\", inplace=True)\n",
        "\n",
        "    # drop \"floor\" and \"expenses\" columns for high null count\n",
        "    df.drop(columns=[\"floor\", \"expenses\"], inplace=True)\n",
        "\n",
        "    # drop high cardinality categorical variables\n",
        "    df.drop(columns=[\"operation\", \"property_type\", \"currency\", \"properati_url\"], inplace=True)\n",
        "\n",
        "    # drop leaky features\n",
        "    df.drop(columns=[\"price\", \"price_aprox_local_currency\", \"price_per_m2\", \"price_usd_per_m2\"], inplace=True)\n",
        "\n",
        "    # drop colums with multicollinearity\n",
        "    #df.drop(columns=[\"surface_total_in_m2\", \"surface_covered_in_m2\"], inplace=True)\n",
        "    df.drop(columns=[\"surface_total_in_m2\", \"rooms\"], inplace=True)\n",
        "\n",
        "\n",
        "    return df\n",
        "\n",
        "# Assemble files in a list\n",
        "files = glob(\"data/buenos-aires-real-estate-*.csv\")\n",
        "files\n",
        "\n",
        "#Write a list comprehension\n",
        "frames = [wrangle(file) for file in files]\n",
        "\n",
        "#Concatenate two or more DataFrames using pandas.\n",
        "df = pd.concat(frames, ignore_index=True)\n",
        "print(df.info())\n",
        "df.head()\n",
        "\n",
        "# Exploration\n",
        "df.isnull().sum()/len(df)\n",
        "df.select_dtypes(\"object\").nunique()\n",
        "sorted(df.columns)\n",
        "corr= df.select_dtypes(\"number\").drop(columns=\"price_aprox_usd\").corr()\n",
        "sns.heatmap(corr)\n",
        "\n",
        "# Split data\n",
        "features = [\"surface_covered_in_m2\",\"lat\", \"lon\", \"neighborhood\"]\n",
        "X_train = df[features]\n",
        "target = \"price_aprox_usd\"\n",
        "y_train = df[target]\n",
        "\n",
        "# build base line model\n",
        "y_mean = y_train.mean()\n",
        "y_pred_baseline = [y_mean]*len(y_train)\n",
        "print(\"Mean apt price:\", round(y_mean,2))\n",
        "\n",
        "print(\"Baseline MAE:\", mean_absolute_error(y_train, y_pred_baseline))\n",
        "\n",
        "# Build an iterative model : Ridge\n",
        "# instantiate model\n",
        "model = make_pipeline(\n",
        "      OneHotEncoder(use_cat_names = True),\n",
        "      SimpleImputer(),\n",
        "      Ridge()\n",
        ")\n",
        "\n",
        "#fit model to training data\n",
        "model.fit(X_train,y_train)\n",
        "\n",
        "#Evaluate model\n",
        "y_pred_training = model.predict(X_train)\n",
        "print(\"Training MAE:\", mean_absolute_error(y_train, y_pred_training))\n",
        "\n",
        "# Test model on test data\n",
        "X_test = pd.read_csv(\"data/buenos-aires-test-features.csv\")\n",
        "y_pred_test = pd.Series(model.predict(X_test))\n",
        "y_pred_test.head()\n",
        "\n",
        "# Create a function make_prediction that takes four arguments (area, lat, lon, and neighborhood\n",
        "# ) and returns your model's prediction for an apartment price.\n",
        "\n",
        "def make_prediction(area, lat, lon, neighborhood):\n",
        "    data= {\n",
        "        \"surface_covered_in_m2\":area,\n",
        "        \"lat\": lat,\n",
        "        \"lon\": lon,\n",
        "        \"neighborhood\":neighborhood\n",
        "    }\n",
        "    df = pd.DataFrame(data, index=[0])\n",
        "    prediction = model.predict(df).round(2)[0]\n",
        "\n",
        "    return f\"Predicted apartment price: ${prediction}\"\n",
        "\n",
        "# Create an interact function in Jupyter Widgets.\n",
        "\n",
        "interact(\n",
        "    make_prediction,\n",
        "    area=IntSlider(\n",
        "        min=X_train[\"surface_covered_in_m2\"].min(),\n",
        "        max=X_train[\"surface_covered_in_m2\"].max(),\n",
        "        value=X_train[\"surface_covered_in_m2\"].mean(),\n",
        "    ),\n",
        "    lat=FloatSlider(\n",
        "        min=X_train[\"lat\"].min(),\n",
        "        max=X_train[\"lat\"].max(),\n",
        "        step=0.01,\n",
        "        value=X_train[\"lat\"].mean(),\n",
        "    ),\n",
        "    lon=FloatSlider(\n",
        "        min=X_train[\"lon\"].min(),\n",
        "        max=X_train[\"lon\"].max(),\n",
        "        step=0.01,\n",
        "        value=X_train[\"lon\"].mean(),\n",
        "    ),\n",
        "    neighborhood=Dropdown(options=sorted(X_train[\"neighborhood\"].unique())),\n",
        ");\n",
        "\n",
        "# Create an interact function in Jupyter Widgets.\n",
        "\n",
        "interact(\n",
        "    make_prediction,\n",
        "    area=IntSlider(\n",
        "        min=X_train[\"surface_covered_in_m2\"].min(),\n",
        "        max=X_train[\"surface_covered_in_m2\"].max(),\n",
        "        value=X_train[\"surface_covered_in_m2\"].mean(),\n",
        "        ),\n",
        "    lat=FloatSlider(\n",
        "        min=X_train[\"lat\"].min(),\n",
        "        max=X_train[\"lat\"].max(),\n",
        "        step=0.01,\n",
        "        value=X_train[\"lat\"].mean(),\n",
        "        ),\n",
        "    lon=FloatSlider(\n",
        "        min=X_train[\"lon\"].min(),\n",
        "        max=X_train[\"lon\"].max(),\n",
        "        step=0.01,\n",
        "        value=X_train[\"lon\"].mean(),\n",
        "        ),\n",
        "    neighborhood=Dropdown(options=sorted(X_train[\"neighborhood\"].unique())),\n",
        ");"
      ]
    }
  ]
}